## 概要
Thinkingモデル（o1等）の中間思考プロセスの挙動調査と対応実装

## 背景
最新のAIモデルでは思考プロセスを含む出力形式が採用されており、これらのモデルでも正確にコマンドやコードを抽出できるようにする必要がある。

## 調査項目

### モデル別の挙動調査
- **OpenAI o1-preview/o1-mini**
  - 思考プロセスの出力形式
  - ストリーミング時の挙動
  - 最終出力との分離方法

- **Claude 3 (thinking mode)**
  - 中間思考の表現形式
  - 実行可能コンテンツの識別方法

- **その他のreasoningモデル**
  - Gemini Pro等の挙動確認

### 技術的調査事項
- APIレスポンスフォーマットの差異
- ストリーミング時のチャンク処理
- 思考部分と実行部分の境界検出
- トークン使用量への影響

## 実装要件

### 機能要件
- 思考プロセスと実行内容の自動分離
- 中間思考の表示/非表示オプション
- 思考プロセスのログ保存
- 実行可能部分のみの抽出

### 技術要件
- ストリーミングパーサーの拡張
- 思考プロセス検出アルゴリズム
- バッファリング戦略の最適化
- APIレスポンス形式の正規化

## 実装タスク
- [ ] 各モデルのAPIレスポンス形式調査（Web検索含む）
- [ ] 思考プロセス検出パターンの定義
- [ ] パーサーの拡張実装
- [ ] モデル固有の設定ファイル作成
- [ ] 統合テストの実装
- [ ] ドキュメント作成

## 調査手法
1. 公式ドキュメントの精査
2. 実際のAPIレスポンス収集と分析
3. コミュニティでの事例調査
4. 実装パターンのベストプラクティス調査

## 受け入れ基準
- [ ] o1モデルで思考と実行内容が正確に分離できる
- [ ] ストリーミング時も正しく処理できる
- [ ] 思考プロセスの表示制御が可能
- [ ] 既存モデルの動作に影響を与えない
- [ ] 新しいthinkingモデルへの対応が容易

## リスク考慮事項
- APIコスト増加（思考トークンの扱い）
- レスポンス時間の増加
- メモリ使用量の増加

## 関連Issue
- #7 のモデル非依存設計に統合
- #4 の出力パーサーを拡張

## ラベル
research, enhancement, model-compatibility, thinking-models

# VLLMCode Configuration

# AI Provider Settings
# OpenAI互換APIのベースURL（例: https://api.openai.com/v1, http://localhost:8000/v1）
VLLM_API_BASE_URL=https://api.openai.com/v1

# APIキー
VLLM_API_KEY=your-api-key-here

# 使用するモデル名
VLLM_MODEL=gpt-4-turbo-preview

# Optional Settings
# 最大トークン数
VLLM_MAX_TOKENS=4096

# 温度パラメータ（0.0-2.0）
VLLM_TEMPERATURE=0.7

# デバッグモード
VLLM_DEBUG=false

# セッション保存ディレクトリ
VLLM_SESSION_DIR=.vllmcode/sessions

# 並列処理の最大数
VLLM_MAX_PARALLEL=5

# プロジェクト解析の深さ
VLLM_ANALYSIS_DEPTH=3

